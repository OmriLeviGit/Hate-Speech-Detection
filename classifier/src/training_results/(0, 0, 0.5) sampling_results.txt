
=== Model evaluation - (0, 0, 0.5) ===
Accuracy score: 0.87 | f1 score: 0.87

Classification Report:
               precision    recall  f1-score   support

           0       0.88      0.87      0.87       230
           1       0.87      0.88      0.88       230

    accuracy                           0.87       460
   macro avg       0.87      0.87      0.87       460
weighted avg       0.87      0.87      0.87       460

Confusion Matrix:
 [[199  31]
 [ 27 203]] 


=== Model evaluation - (0, 0, 0.5) ===
Accuracy score: 0.81 | f1 score: 0.81

Classification Report:
               precision    recall  f1-score   support

           0       0.81      0.81      0.81       230
           1       0.81      0.80      0.81       230

    accuracy                           0.81       460
   macro avg       0.81      0.81      0.81       460
weighted avg       0.81      0.81      0.81       460

Confusion Matrix:
 [[186  44]
 [ 45 185]] 


=== Model evaluation - (0, 0, 0.5) ===
Accuracy score: 0.83 | f1 score: 0.83

Classification Report:
               precision    recall  f1-score   support

           0       0.83      0.82      0.83       230
           1       0.82      0.83      0.83       230

    accuracy                           0.83       460
   macro avg       0.83      0.83      0.83       460
weighted avg       0.83      0.83      0.83       460

Confusion Matrix:
 [[189  41]
 [ 39 191]] 


=== Model evaluation - (0, 0, 0.5) ===
Accuracy score: 0.83 | f1 score: 0.83

Classification Report:
               precision    recall  f1-score   support

           0       0.85      0.81      0.83       230
           1       0.82      0.86      0.84       230

    accuracy                           0.83       460
   macro avg       0.83      0.83      0.83       460
weighted avg       0.83      0.83      0.83       460

Confusion Matrix:
 [[186  44]
 [ 33 197]] 


=== Model evaluation - (0, 0, 0.5) ===
Accuracy score: 0.81 | f1 score: 0.81

Classification Report:
               precision    recall  f1-score   support

           0       0.82      0.79      0.81       230
           1       0.80      0.83      0.81       230

    accuracy                           0.81       460
   macro avg       0.81      0.81      0.81       460
weighted avg       0.81      0.81      0.81       460

Confusion Matrix:
 [[182  48]
 [ 39 191]] 


=== Model evaluation - (0, 0, 0.5) ===
Accuracy score: 0.82 | f1 score: 0.82

Classification Report:
               precision    recall  f1-score   support

           0       0.86      0.76      0.81       230
           1       0.79      0.87      0.83       230

    accuracy                           0.82       460
   macro avg       0.82      0.82      0.82       460
weighted avg       0.82      0.82      0.82       460

Confusion Matrix:
 [[175  55]
 [ 29 201]] 


=== Model evaluation - (0, 0, 0.5) ===
Accuracy score: 0.81 | f1 score: 0.81

Classification Report:
               precision    recall  f1-score   support

           0       0.81      0.80      0.81       230
           1       0.81      0.81      0.81       230

    accuracy                           0.81       460
   macro avg       0.81      0.81      0.81       460
weighted avg       0.81      0.81      0.81       460

Confusion Matrix:
 [[185  45]
 [ 43 187]] 


=== Model evaluation - (0, 0, 0.5) ===
Accuracy score: 0.81 | f1 score: 0.81

Classification Report:
               precision    recall  f1-score   support

           0       0.83      0.78      0.80       230
           1       0.79      0.84      0.82       230

    accuracy                           0.81       460
   macro avg       0.81      0.81      0.81       460
weighted avg       0.81      0.81      0.81       460

Confusion Matrix:
 [[179  51]
 [ 36 194]] 


=== Model evaluation - (0, 0, 0.5) ===
Accuracy score: 0.84 | f1 score: 0.84

Classification Report:
               precision    recall  f1-score   support

           0       0.83      0.85      0.84       230
           1       0.85      0.82      0.83       230

    accuracy                           0.84       460
   macro avg       0.84      0.84      0.84       460
weighted avg       0.84      0.84      0.84       460

Confusion Matrix:
 [[196  34]
 [ 41 189]] 


=== Model evaluation - (0, 0, 0.5) ===
Accuracy score: 0.83 | f1 score: 0.83

Classification Report:
               precision    recall  f1-score   support

           0       0.83      0.84      0.84       230
           1       0.84      0.83      0.83       230

    accuracy                           0.83       460
   macro avg       0.83      0.83      0.83       460
weighted avg       0.83      0.83      0.83       460

Confusion Matrix:
 [[194  36]
 [ 40 190]] 

