
=== Model evaluation - (0.3, 0.45, 0.6) ===
Accuracy score: 0.88 | f1 score: 0.88

Classification Report:
               precision    recall  f1-score   support

           0       0.89      0.92      0.90       345
           1       0.87      0.83      0.85       230

    accuracy                           0.88       575
   macro avg       0.88      0.87      0.87       575
weighted avg       0.88      0.88      0.88       575

Confusion Matrix:
 [[316  29]
 [ 40 190]] 


=== Model evaluation - (0.3, 0.45, 0.6) ===
Accuracy score: 0.86 | f1 score: 0.86

Classification Report:
               precision    recall  f1-score   support

           0       0.89      0.87      0.88       345
           1       0.82      0.84      0.83       230

    accuracy                           0.86       575
   macro avg       0.85      0.86      0.86       575
weighted avg       0.86      0.86      0.86       575

Confusion Matrix:
 [[301  44]
 [ 36 194]] 


=== Model evaluation - (0.3, 0.45, 0.6) ===
Accuracy score: 0.88 | f1 score: 0.88

Classification Report:
               precision    recall  f1-score   support

           0       0.89      0.90      0.90       345
           1       0.85      0.83      0.84       230

    accuracy                           0.88       575
   macro avg       0.87      0.87      0.87       575
weighted avg       0.88      0.88      0.88       575

Confusion Matrix:
 [[312  33]
 [ 38 192]] 


=== Model evaluation - (0.3, 0.45, 0.6) ===
Accuracy score: 0.86 | f1 score: 0.86

Classification Report:
               precision    recall  f1-score   support

           0       0.88      0.90      0.89       345
           1       0.84      0.81      0.82       230

    accuracy                           0.86       575
   macro avg       0.86      0.85      0.85       575
weighted avg       0.86      0.86      0.86       575

Confusion Matrix:
 [[309  36]
 [ 44 186]] 


=== Model evaluation - (0.3, 0.45, 0.6) ===
Accuracy score: 0.86 | f1 score: 0.86

Classification Report:
               precision    recall  f1-score   support

           0       0.87      0.90      0.89       345
           1       0.85      0.79      0.82       230

    accuracy                           0.86       575
   macro avg       0.86      0.85      0.85       575
weighted avg       0.86      0.86      0.86       575

Confusion Matrix:
 [[312  33]
 [ 48 182]] 


=== Model evaluation - (0.3, 0.45, 0.6) ===
Accuracy score: 0.87 | f1 score: 0.87

Classification Report:
               precision    recall  f1-score   support

           0       0.90      0.88      0.89       345
           1       0.83      0.86      0.84       230

    accuracy                           0.87       575
   macro avg       0.87      0.87      0.87       575
weighted avg       0.87      0.87      0.87       575

Confusion Matrix:
 [[305  40]
 [ 33 197]] 


=== Model evaluation - (0.3, 0.45, 0.6) ===
Accuracy score: 0.85 | f1 score: 0.85

Classification Report:
               precision    recall  f1-score   support

           0       0.87      0.88      0.88       345
           1       0.82      0.80      0.81       230

    accuracy                           0.85       575
   macro avg       0.85      0.84      0.85       575
weighted avg       0.85      0.85      0.85       575

Confusion Matrix:
 [[305  40]
 [ 45 185]] 


=== Model evaluation - (0.3, 0.45, 0.6) ===
Accuracy score: 0.85 | f1 score: 0.85

Classification Report:
               precision    recall  f1-score   support

           0       0.87      0.88      0.88       345
           1       0.82      0.80      0.81       230

    accuracy                           0.85       575
   macro avg       0.85      0.84      0.85       575
weighted avg       0.85      0.85      0.85       575

Confusion Matrix:
 [[305  40]
 [ 45 185]] 


=== Model evaluation - (0.3, 0.45, 0.6) ===
Accuracy score: 0.88 | f1 score: 0.88

Classification Report:
               precision    recall  f1-score   support

           0       0.88      0.92      0.90       345
           1       0.87      0.81      0.84       230

    accuracy                           0.88       575
   macro avg       0.88      0.87      0.87       575
weighted avg       0.88      0.88      0.88       575

Confusion Matrix:
 [[318  27]
 [ 44 186]] 


=== Model evaluation - (0.3, 0.45, 0.6) ===
Accuracy score: 0.86 | f1 score: 0.85

Classification Report:
               precision    recall  f1-score   support

           0       0.86      0.90      0.88       345
           1       0.84      0.79      0.81       230

    accuracy                           0.86       575
   macro avg       0.85      0.84      0.85       575
weighted avg       0.86      0.86      0.85       575

Confusion Matrix:
 [[311  34]
 [ 49 181]] 

